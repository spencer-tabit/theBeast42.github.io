---
title: "Trends within All-NBA Team Data"
author: "Spencer Tabit"
output: html_document
knit: (function(inputFile, encoding) { rmarkdown::render(inputFile, encoding = encoding, output_file = file.path(dirname(inputFile), 'index.html')) })
---

#Introduction

The National Basketball Association is going through a lot of changes nowdays with the rise of machine learning and big data. NBA teams are taking data and statistics and analyzing them in order to gain a competitive advantage just like many baseball teams started to do during the Moneyball era. While analyzing how these trends have affected the NBA and the All-NBA teams in particular, I will go through the data science pipeline, and explain how to do the same analysis. Some important trends to consider will be the rise of 3 pointers and how to predict All-NBA players, so teams know how to predict super max players. More on the supermax contract can be read about in this article: https://www.chicagotribune.com/sports/ct-spt-nba-supermax-contract-20181221-story.html

#Required Tools

Below is an overview of some of the more heavily used libraries and what their use is.

readr => Important for methods like read_csv() which let you read in data from csv files stored locally on your computer.
dplyr => Contains all the basic methods for data manipulation like mutate(), select(), filter(), summarise(), and arrange(). This methods will be used repeatedly throughout the tutorial.
ggplot2 => This package contains the essentails for graphically displaying data. This link, https://github.com/rstudio/cheatsheets/blob/master/data-visualization-2.1.pdf , goes to a nice cheat sheet that illustrates all the information a coder needs to make the perfect visuals. 
rvest => Let's us scrape data from websites. The methods in this package will be useful when we have to copy a table from Wikipedia.
magrittr => The package also lets your use %>% or pipe operator which is a functional programming feature. The pipe operator lets you push the data frame forward to the next function.
stringr => This is used for manipulating string and doing regex while the data is getting cleaned.
broom => The broom package let's us perform different types of linear regression and other stastical tests while returning a tidy data frame.

```{r setup, include=TRUE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(readr)
library(dplyr)
library(ggplot2)
library(rvest)
library(magrittr)
library(stringr)
library(broom)
library(knitr)
library(ROCR)
library(tidyr)
library(tidyverse)
library(tibble)
```

#Tidying Up Data

In this step, I am taking that CSV files that contain the professional basketball player statistics for a season, and loading them into dataframes. I then use the rbind method to merge everything into one gaint dataframe that contains all the data. I tidy up the frames by adding in the season, so I can analyze trends across seasons. The data orginally comes from https://github.com/aaronS7/nba-datasets. I only took data from my time frame and in the regular season. Some important basketball stat terms to know are PTS = Points, REB = Rebound, EFF = effiency (https://en.wikipedia.org/wiki/Efficiency_(basketball)) which involves a bunch of counting stats to create, and 3PA = 3 pointers attempted.

```{r message = FALSE, warning=FALSE}
setwd("~/College/CMSC320/Final Project/data/regularSeason")

regular_seasons <- 
  rbind( #rbind mergess two data frames that have the same columns together
    read_csv("nba_1988-89.csv") %>% mutate(season = "1988-89"),
    read_csv("nba_1989-90.csv") %>% mutate(season = "1989-90")
  ) %>%
  rbind(
    read_csv("nba_1990-91.csv") %>% mutate(season = "1990-91")
  ) %>%
  rbind(
    read_csv("nba_1991-92.csv") %>% mutate(season = "1991-92")
  ) %>%
  rbind (
    read_csv("nba_1992-93.csv") %>% mutate(season = "1992-93")
  ) %>%
  rbind(
    read_csv("nba_1993-94.csv") %>% mutate(season = "1993-94")
  ) %>%
  rbind(
    read_csv("nba_1994-95.csv") %>% mutate(season = "1994-95")
  ) %>%
  rbind(
    read_csv("nba_1995-96.csv") %>% mutate(season = "1995-96")
  ) %>%
  rbind(
    read_csv("nba_1996-97.csv") %>% mutate(season = "1996-97")
  ) %>%
  rbind(
    read_csv("nba_1997-98.csv") %>% mutate(season = "1997-98")
  ) %>%
  rbind(
    read_csv("nba_1998-99.csv") %>% mutate(season = "1998-99")
  ) %>%
  rbind(
    read_csv("nba_1999-00.csv") %>% mutate(season = "1999-00")
  ) %>% 
  rbind(
    read_csv("nba_2000-01.csv") %>% mutate(season = "2000-01")
  ) %>% 
  rbind(
    read_csv("nba_2001-02.csv") %>% mutate(season = "2001-02")
  ) %>% 
  rbind(
    read_csv("nba_2002-03.csv") %>% mutate(season = "2002-03")
  ) %>% 
  rbind(
    read_csv("nba_2003-04.csv") %>% mutate(season = "2003-04")
  ) %>% 
  rbind(
    read_csv("nba_2004-05.csv") %>% mutate(season = "2004-05")
  ) %>% 
  rbind(
    read_csv("nba_2005-06.csv") %>% mutate(season = "2005-06")
  ) %>% 
  rbind(
    read_csv("nba_2006-07.csv") %>% mutate(season = "2006-07")
  ) %>% 
  rbind(
    read_csv("nba_2007-08.csv") %>% mutate(season = "2007-08")
  ) %>% 
  rbind(
    read_csv("nba_2008-09.csv") %>% mutate(season = "2008-09")
  ) %>% 
  rbind(
    read_csv("nba_2009-10.csv") %>% mutate(season = "2009-10")
  ) %>% 
  rbind(
    read_csv("nba_2010-11.csv") %>% mutate(season = "2010-11")
  ) %>% 
  rbind(
    read_csv("nba_2011-12.csv") %>% mutate(season = "2011-12")
  ) %>% 
  rbind(
    read_csv("nba_2012-13.csv") %>% mutate(season = "2012-13")
  ) %>% 
  rbind(
    read_csv("nba_2013-14.csv") %>% mutate(season = "2013-14")
  ) %>% 
  rbind(
    read_csv("nba_2014-15.csv") %>% mutate(season = "2014-15")
  ) %>% 
  rbind(
    read_csv("nba_2015-16.csv") %>% mutate(season = "2015-16")
  ) %>% 
  rbind(
    read_csv("nba_2016-17.csv") %>% mutate(season = "2016-17")
  ) %>% 
  rbind(
    read_csv("nba_2017-18.csv") %>% mutate(season = "2017-18")
  ) %>%
  mutate(player = str_trim(Name)) #We need to remove trailing whitespace or the join will not work later on.

regular_seasons$Name <- NULL #We don't need name anymore since we have replaced it with player.

regular_seasons
```
#Web Scrapping and Cleaning Data
In this sections I scrape Wikipedia for the All-NBA teams from 1988 to 2018. This gives me a larger enough set of data to join with my regular season. This allows me to compare the two datasets and figure out which differences between regular NBA players and All-NBA players.

```{r message = FALSE, warning=FALSE}
all_nba_team_players_url <- "https://en.wikipedia.org/wiki/All-NBA_Team"

all_nba_team_players_data <- all_nba_team_players_url %>%
  read_html() %>%
  html_node("#mw-content-text > div > table:nth-child(24)") %>% 
  #Using inspect on your favorite web browser you can find the table and copy the selector when it gives you the option.
  html_table(fill=TRUE) %>%
  set_colnames(c("season", "first_players", "first_players_team", "second_players", "second_players_team", "third_players", "third_players_team")) %>%
  as_tibble()

all_nba_team_players_data <- all_nba_team_players_data %>%
  slice(2:151)

all_nba_team_first_data <- all_nba_team_players_data %>%
  mutate(is_all_nba = "Yes") %>%
  rename(player = first_players) %>%
  select(season, player, is_all_nba)

all_nba_team_second_data <- all_nba_team_players_data %>%
  mutate(is_all_nba = "Yes") %>%
  mutate(player = second_players) %>%
  select(season, player, is_all_nba)

all_nba_team_third_data <- all_nba_team_players_data %>%
  mutate(is_all_nba = "Yes") %>%
  mutate(player = third_players) %>%
  select(season, player, is_all_nba)

#We want a full join because we know none of the values are going to match. We just want the values to be merged into one table without anything being dropped.
all_nba_team_players_data <- all_nba_team_first_data %>%
  full_join(all_nba_team_second_data, by= c("season", "player", "is_all_nba")) %>%
  full_join(all_nba_team_third_data, by =c("season", "player", "is_all_nba")) %>%
  arrange(season)

#The season values and player names were not very character friendly, so I used some string manipulation to make them compatible with our local data.
all_nba_team_players_data <- all_nba_team_players_data %>%
  mutate(player = str_extract(player, "^(\\w|'|-)* [A-Za-z]*")) %>%
  mutate(season = str_c(str_extract(season, "^\\d*"),str_extract(str_trim(season), "\\d*$"), sep = "-"))

all_nba_team_players_data
```  
#Putting the data together
I put the data together in one place, so I could have all the data in one dataframe. This makes it easier to select the data I need into a new frame or I can easily compare any two attributes in a graph with this dataset.
```{r}
#I used a left join because I didn't want to include any data about All-NBA players without matching statistics. Without having the statistics associated with the player I wouldn't be any calculations making them not very useful.
regular_seasons <- regular_seasons %>%
  left_join(all_nba_team_players_data, by = c("player", "season")) %>%
  mutate(is_all_nba = if_else(is.na(is_all_nba), "No", "Yes"))

regular_seasons
``` 
#Exploratory Data Analysis, Graphing, and Linear Regression
Now, that the data has been cleaned and consolidated, I have the ability to explore and find out the story the data is telling. First, I remembered from the many news articles I have read that the NBA was entering the 3 pt era. Players like Stephen Curry and teams like the Houston Rockets had been pushing the league as a whole to become disciples of the three ball. In order, to check if this claim was true, I started my exploration by graphing how many 3 pt shots had been attempted every season.
```{r}
threes_per_season <- regular_seasons%>%
  group_by(season) %>%
  summarize(sum_of_3PA = sum(`3PA`)) %>%
  mutate(season = strtoi(str_extract(season, "^\\d*")))
#I changed season to a numeric value because I wanted to be able to perform analysis on the linear regression later on.
threes_per_season %>%
  ggplot(aes(x=season, y =sum_of_3PA)) +
  geom_bar(stat = "identity") +
  geom_smooth(method = lm) +
  labs(title="Three Pointers Attempted Per Season",
         x = "Season",
         y = "Three Pointers Attempted") +
  theme(axis.text.x = element_text(angle=90, vjust=0.5))
```
The graph clearly shows a positive relationship between year and three pointers attempted, so it makes sense to look at the linear regression more closely. Let's assume the null hypothesis holds and there is no relationship between year and three pointers attempted.
```{r}
threes_per_season_fit <- lm(sum_of_3PA~season, data=threes_per_season)

threes_per_season_stats <- threes_per_season_fit %>%
  tidy()

threes_per_season_stats
```
I reject the null hypothesis of no relationship between year and three points attempted because the linear model between year and three points attempted shows that change of 16.9 is statistically significant. The change is statistically significant because7.852949e-11 is less than .05 by a lot.
```{r}
threes_for_players <- regular_seasons%>%
  mutate(season = strtoi(str_extract(season, "^\\d*")))
#The color add-on to the ggplot lets the graph know that it needs to label all the two categories of is_all_nba different colors, so they can be told apart in the scattterplot.
threes_for_players %>%
  ggplot(aes(x=season, y = `3PA`, color = is_all_nba)) +
  geom_point() +
  geom_smooth(method = lm) +
  labs(title="Three Pointers Attempted by Players in A Season",
         x = "Season",
         y = "Three Pointers Attempted") +
  theme(axis.text.x = element_text(angle=90, vjust=0.5))
```
Looking at this graph, the relationship isn't that different when we compare All-NBA players and regular players. Exploring more would give us more insight and allow us to figure out the best value to compare types of players on. This could eventually lead to a good value to categorize All-NBA players on.
```{r}
average_players <- regular_seasons%>%
  group_by(is_all_nba) %>%
  summarise(mean_EFF = mean(EFF), mean_PTS = mean(PTS), mean_REB = mean(REB), mean_AST = mean(AST), mean_STL = mean(STL), mean_BLK = mean(BLK), mean_TOV = mean(TOV))

average_players
```
Looking at the two types of players, we can see that EFF or efficeincy is an interesting option to look at further. There is a wide differnece between an All-NBA and normal players efficeincy. Also, it makes sense that All-NBA player has better averages because they are the better player across the board. It is also important to note that EFF takes into account PTS, REB, and other counting stats already, so we can use it instead of having to consider all those values at once.

```{r}
regular_seasons%>%
  ggplot(aes(x=season, y =EFF, color = is_all_nba)) +
  geom_point() +
  geom_smooth(method=lm) +
  labs(title="Efficiency by Season",
         x = "Season",
         y = "Efficiency") +
  theme(axis.text.x = element_text(angle=90, vjust=0.5))
```
This is an intriguing graph because it shows us that efficiency has been very good at seperating out All-NBA players. They all have extremely high effiency so we only have to look at the top of the line for each year to make guesses about what players will be All-NBA. This tells me that I should take a deeper look at classifying the data.

#Classification
Since we decided to use EFF as starting point to classify whether or not a player is on the All-NBA team, we should try to figure out well our model is doing. The two models below use EFF and some other other attributes to try to predict whether a player in our dataset is All-NBA. I thought the second model did a lear good job at limit false positives and true negatives.

```{r message = FALSE, warning= FALSE}
library(MASS)
all_nba_fit1 <- lda(as.factor(is_all_nba) ~ EFF, regular_seasons)
lda_pred <- predict(all_nba_fit1, data=regular_seasons)
print(table(predicted=lda_pred$class, observed=regular_seasons$is_all_nba))

``` 

```{r}
all_nba_fit2 <- lda(as.factor(is_all_nba) ~ EFF * PTS * REB, regular_seasons)
lda_pred2 <- predict(all_nba_fit2, data=regular_seasons)
print(table(predicted=lda_pred2$class, observed=regular_seasons$is_all_nba))
``` 

```{r echo=FALSE}
pred2 <- prediction(lda_pred2$posterior[,"Yes"], regular_seasons$is_all_nba)

layout(cbind(1,2))
plot(performance(pred2, "tpr"))
plot(performance(pred2, "fpr"))
``` 
The TPR stays very close to 1 the entire time even as our cutoff goes to 1. This means we are generally getting true postives. On the other hand, the false positive rate almost immediately plummetts to zero signalling that there are almost no false positives being created to distract us.
```{r}
auc <- unlist(performance(pred2, "auc")@y.values)
plot(performance(pred2, "tpr", "fpr"), 
     main=paste("LDA AUROC=", round(auc, 2)), 
     lwd=1.4, cex.lab=1.7, cex.main=1.5)
```
The ROC curve is a way of describing the TPR and FPR. It tells how much model is capable of deciding between our two choices. The higher the AUROC the better our model is at predicting between the binary decision. Obviously, 0.98 is an extremely high AUROC, so our choice of model is very good. To learn more about ROC and AUROC check out this link: https://towardsdatascience.com/understanding-auc-roc-curve-68b2303cc9c5

#Conclusion

In effect, it is possible to accurately determine if a player is goign to be a All-NBA player which is helpful to teams wondering what they might have to prepare to give out a supermax. Also, we saw that All-NBA players and normal players will both most likely increase the amounts of three pointers they take. Finally, I just scratched the surface of NBA data analysis. Many NBA teams have even more sophisticated data science questions like how accuracetely can we predict the success of rookies 5 years down the line. 